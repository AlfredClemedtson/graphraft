{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-30T08:45:35.508572Z",
     "start_time": "2025-01-30T08:45:35.506155Z"
    }
   },
   "source": [
    "from http.cookiejar import unmatched\n",
    "from xml.etree.ElementInclude import include\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "\n",
    "load_dotenv('db.env', override=True)\n",
    "NEO4J_URI = os.getenv('NEO4J_URI')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ],
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T09:26:15.443475Z",
     "start_time": "2025-01-31T09:26:13.739786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Functions for entity recognition\n",
    "def identify_entities(question: str):\n",
    "    multi_shot_examples = [\n",
    "        {\"question\" : \"Which anatomical structures lack the expression of genes or proteins involved in the interaction with the fucose metabolism pathway?\", \"answer\" : \"fucose metabolism\"},\n",
    "        {\"question\" : \"What liquid drugs target the A2M gene/protein and bind to the PDGFR-beta receptor?\", \"answer\" : \"A2M gene/protein|PDGFR-beta receptor\"},\n",
    "        {\"question\" : \"Which genes or proteins are linked to melanoma and also interact with TNFSF8?\", \"answer\" : \"melanoma|TNFSF8\"},\n",
    "    ]\n",
    "    client = OpenAI()\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You area a knowledgeable assistant which identifies medical entities in the given sentences. Separate entities using '|'.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Q:\\\"{multi_shot_examples[0]['question']}\\\"\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"A:{multi_shot_examples[0]['answer']}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Q:\\\"{multi_shot_examples[1]['question']}\\\"\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"A:{multi_shot_examples[0]['answer']}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Q:\\\"{multi_shot_examples[2]['question']}\\\"\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"A:{multi_shot_examples[0]['answer']}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Q:\\\"{question}\"},\n",
    "        ]\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    entities = response.lstrip('A:').split('|')\n",
    "    return entities\n",
    "\n",
    "with GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD)) as driver:\n",
    "    res = driver.execute_query(\"\"\"MATCH (n) RETURN n.name AS name\"\"\")\n",
    "    lower2original = {}\n",
    "    for rec in res.records:\n",
    "        new_name = rec['name'].lower()\n",
    "        lower2original[new_name] = lower2original.get(new_name, []) + [rec['name']]\n",
    "\n",
    "def match_entities(entity_names):\n",
    "    k=5\n",
    "    unmatched_entity_names = []\n",
    "    matched_entity_names = []\n",
    "    for entity in entity_names:\n",
    "        if entity.lower() in lower2original.keys():\n",
    "            matched_entity_names.extend(lower2original[entity.lower()])\n",
    "        elif entity != '': #cannot be encoded\n",
    "            unmatched_entity_names.append(entity)\n",
    "    try:\n",
    "        if len(unmatched_entity_names) > 0:\n",
    "            with GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD)) as driver:\n",
    "                res = driver.execute_query(\"\"\"\n",
    "                                        CALL genai.vector.encodeBatch($names, 'OpenAI', { token: $api_key }) YIELD vector AS entityNameEmbs\n",
    "                                        CALL db.index.vector.queryNodes('nameEmbedding', $k, entityNameEmbs) YIELD node\n",
    "                                        RETURN node.name AS name\"\"\", parameters_={'names': unmatched_entity_names, 'k': k, 'api_key': OPENAI_API_KEY})\n",
    "            top1_similar_names = [res.records[i]['name'] for i in range(0,len(res.records),k)]\n",
    "            matched_entity_names += top1_similar_names\n",
    "    except:\n",
    "        print(unmatched_entity_names)\n",
    "    return matched_entity_names\n",
    "\n",
    "def add_entities(data):\n",
    "    question = data['question']\n",
    "    identified_entities = identify_entities(question)\n",
    "    matched_entities = match_entities(identified_entities)\n",
    "    data['predicted_entities'] = matched_entities\n",
    "    return data"
   ],
   "id": "56136a6aeed7d67e",
   "outputs": [],
   "execution_count": 343
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T09:26:17.430261Z",
     "start_time": "2025-01-31T09:26:17.425996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Helpers for cypher generation\n",
    "def cypher2path(cypher_query: str) -> list[tuple[str, str, str, str]]:\n",
    "    path = re.findall(r\"(?:\\(|-\\[)(x|r)(\\d):([^ \\)\\]]+)(?: \\{name: \\\"(.+)\\\"\\})?(?:\\)|\\]-)\", cypher_query)\n",
    "    return path\n",
    "\n",
    "def block2cypher(x_r: str, num: str, label_or_type: str, name: str) -> str:\n",
    "    if x_r == 'x':\n",
    "        prop_string = f\" {{name: \\\"{name}\\\"}}\" if name != '' else \"\"\n",
    "        return f\"(x{num}:{label_or_type}{prop_string})\"\n",
    "    elif x_r == 'r':\n",
    "        return f\"-[r{num}:{label_or_type}]-\"\n",
    "\n",
    "def path2cypher(path: list[tuple[str, str, str, str]]) -> str:\n",
    "    query = \"MATCH \"\n",
    "    for x_r, num, labelOrType, name in path:\n",
    "        if x_r == 'x' or x_r == 'r':\n",
    "            query += block2cypher(x_r, num, labelOrType, name)\n",
    "        elif x_r == '':\n",
    "            query += f\" RETURN x{num}.name as name\"\n",
    "    return query"
   ],
   "id": "dbdb0600a3f6b2a7",
   "outputs": [],
   "execution_count": 344
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T11:20:19.063065Z",
     "start_time": "2025-01-31T11:20:19.058477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_evaluated_paths(driver, src_names: list[str], tgt_ids: list[str]) -> (list[tuple[str, str, str, str]], float, float):\n",
    "    query_1hop = \"\"\"UNWIND $src_names AS srcName\n",
    "                    MATCH (src {name: srcName})-[r]-(tgt)\n",
    "                    \n",
    "                    RETURN labels(src)[1] AS label1, src.name AS name1, type(r) AS type1, labels(tgt)[1] AS label2, size([t IN collect(DISTINCT tgt) WHERE t.nodeId in $tgt_ids| t]) AS correctCnt, count(DISTINCT tgt) AS totalCnt\"\"\"\n",
    "    \n",
    "    query_2hop = \"\"\"UNWIND $src_names AS srcName\n",
    "                    MATCH (src1 {name: srcName})-[r1]-(var)-[r2]-(tgt) WHERE tgt <> src1\n",
    "                    \n",
    "                    RETURN labels(src1)[1] AS label1, src1.name AS name1, type(r1) AS type1, labels(var)[1] AS label2, type(r2) AS type2, labels(tgt)[1] AS label3, size([t IN collect(DISTINCT tgt) WHERE t.nodeId in $tgt_ids| t]) AS correctCnt, count(DISTINCT tgt) AS totalCnt\"\"\"\n",
    "    \n",
    "    query_2path = \"\"\"UNWIND $src_names AS srcName1\n",
    "                     UNWIND $src_names AS srcName2\n",
    "                     MATCH (src1 {name: srcName1})-[r1]-(tgt)-[r2]-(src2 {name: srcName2}) WHERE src1 <> src2\n",
    "    \n",
    "                     RETURN labels(src1)[1] AS label1, src1.name AS name1, type(r1) AS type1, labels(tgt)[1] AS label2, type(r2) AS type2, labels(src2)[1] AS label3, src2.name AS name3, size([t IN collect(DISTINCT tgt) WHERE t.nodeId in $tgt_ids| t]) AS correctCnt, count(DISTINCT tgt) AS totalCnt\"\"\"\n",
    "    \n",
    "    cyphers = []\n",
    "    hits = []\n",
    "    num_results = []\n",
    "    for res in driver.execute_query(query_1hop, parameters_={'src_names': src_names, 'tgt_ids': tgt_ids}).records:\n",
    "        path = [('x', 1, res['label1'], res['name1']), ('r', 1, res['type1'], \"\"), ('x', 2, res['label2'], \"\"), ('', 2, \"\", \"\")]\n",
    "        cyphers.append(path2cypher(path))\n",
    "        hits.append(res['correctCnt'])\n",
    "        num_results.append(res['totalCnt'])\n",
    "        \n",
    "    for res in driver.execute_query(query_2hop, parameters_={'src_names': src_names, 'tgt_ids': tgt_ids}).records:\n",
    "        path = [('x', 1, res['label1'], res['name1']), ('r', 1, res['type1'], \"\"), ('x', 2, res['label2'], \"\"),\n",
    "                      ('r', 2, res['type2'], \"\"), ('x', 3, res['label3'], \"\"), ('', 3, \"\", \"\")]\n",
    "        cyphers.append(path2cypher(path))\n",
    "        hits.append(res['correctCnt'])\n",
    "        num_results.append(res['totalCnt'])\n",
    "        \n",
    "    for res in driver.execute_query(query_2path, parameters_={'src_names': src_names, 'tgt_ids': tgt_ids}).records:\n",
    "        path = [('x', 1, res['label1'], res['name1']), ('r', 1, res['type1'], \"\"), ('x', 2, res['label2'], \"\"),\n",
    "                      ('r', 2, res['type2'], \"\"), ('x', 3, res['label3'], res['name3']), ('', 2, \"\", \"\")]\n",
    "        cyphers.append(path2cypher(path))\n",
    "        hits.append(res['correctCnt'])\n",
    "        num_results.append(res['totalCnt'])\n",
    "\n",
    "    return cyphers, hits, num_results\n",
    "\n",
    "def add_cypher_data(data, driver, include_stats=False):\n",
    "    src_names = data['predicted_entities']\n",
    "    tgt_ids = eval(data['answer_ids']) if include_stats else []\n",
    "    data['cyphers'], data['hits'], data['num_results'] = get_evaluated_paths(driver, src_names, tgt_ids)\n",
    "    return data"
   ],
   "id": "d6c468bb4d34a2cc",
   "outputs": [],
   "execution_count": 389
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T09:26:20.431237Z",
     "start_time": "2025-01-31T09:26:20.421384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#All data to load\n",
    "qa = load_from_disk('prime-data/qa')"
   ],
   "id": "3cae2845c12dc104",
   "outputs": [],
   "execution_count": 346
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T10:11:54.020454Z",
     "start_time": "2025-01-31T09:26:21.278360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Entity matching\n",
    "qa_with_ner = qa.map(add_entities, num_proc=8)\n",
    "qa_with_ner.save_to_disk('prime-data/qa_with_ner')"
   ],
   "id": "428a023ccdac72e3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=8): 100%|██████████| 6162/6162 [21:03<00:00,  4.88 examples/s]  \n",
      "Map (num_proc=8): 100%|██████████| 2241/2241 [07:44<00:00,  4.82 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 2801/2801 [16:42<00:00,  2.79 examples/s]  \n",
      "Saving the dataset (1/1 shards): 100%|██████████| 6162/6162 [00:00<00:00, 1019860.36 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2241/2241 [00:00<00:00, 772217.82 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2801/2801 [00:00<00:00, 915114.93 examples/s]\n"
     ]
    }
   ],
   "execution_count": 347
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T12:21:40.152989Z",
     "start_time": "2025-01-31T11:22:26.453808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find all possible patterns from the identified source nodes\n",
    "with GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD)) as driver:\n",
    "    qa_with_cyphers = qa_with_ner.map(lambda x: add_cypher_data(x, driver, include_stats=True), num_proc=8) #includes stats also for test set, make sure to ignore later!\n",
    "qa_with_cyphers['test'] = qa_with_cyphers['test'].remove_columns(['hits', 'num_results'])\n",
    "qa_with_cyphers.save_to_disk('prime-data/qa_with_cyphers')"
   ],
   "id": "e51fe49c4693a748",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=8): 100%|██████████| 6162/6162 [25:00<00:00,  4.11 examples/s]  \n",
      "Map (num_proc=8): 100%|██████████| 2241/2241 [21:39<00:00,  1.73 examples/s]   \n",
      "Map (num_proc=8): 100%|██████████| 2801/2801 [12:33<00:00,  3.71 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 6162/6162 [00:00<00:00, 205434.48 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2241/2241 [00:00<00:00, 281142.44 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2801/2801 [00:00<00:00, 377757.09 examples/s]\n"
     ]
    }
   ],
   "execution_count": 392
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
