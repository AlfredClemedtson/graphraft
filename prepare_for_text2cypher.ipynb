{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from neo4j import GraphDatabase\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from datasets import load_from_disk\n",
    "\n",
    "from cypher_parsing import path2cypher\n",
    "\n",
    "load_dotenv('db.env', override=True)\n",
    "NEO4J_URI = os.getenv('NEO4J_URI')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ],
   "id": "21446943591239b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Functions for entity recognition\n",
    "def identify_entities(question: str):\n",
    "    multi_shot_examples = [\n",
    "        {\"question\" : \"Which anatomical structures lack the expression of genes or proteins involved in the interaction with the fucose metabolism pathway?\", \"answer\" : \"fucose metabolism\"},\n",
    "        {\"question\" : \"What liquid drugs target the A2M gene/protein and bind to the PDGFR-beta receptor?\", \"answer\" : \"A2M gene/protein|PDGFR-beta receptor\"},\n",
    "        {\"question\" : \"Which genes or proteins are linked to melanoma and also interact with TNFSF8?\", \"answer\" : \"melanoma|TNFSF8\"},\n",
    "    ]\n",
    "    client = OpenAI()\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You area a knowledgeable assistant which identifies medical entities in the given sentences. Separate entities using '|'.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Q:\\\"{multi_shot_examples[0]['question']}\\\"\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"A:{multi_shot_examples[0]['answer']}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Q:\\\"{multi_shot_examples[1]['question']}\\\"\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"A:{multi_shot_examples[1]['answer']}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Q:\\\"{multi_shot_examples[2]['question']}\\\"\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"A:{multi_shot_examples[2]['answer']}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Q:\\\"{question}\"},\n",
    "        ]\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    entities = response.lstrip('A:').split('|')\n",
    "    return entities\n",
    "\n",
    "with GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD)) as driver:\n",
    "    res = driver.execute_query(\"\"\"MATCH (n) RETURN n.name AS name\"\"\")\n",
    "    lower2original = {}\n",
    "    for rec in res.records:\n",
    "        new_name = rec['name'].lower()\n",
    "        lower2original[new_name] = lower2original.get(new_name, []) + [rec['name']]\n",
    "\n",
    "def match_entities(entity_names):\n",
    "    k=5\n",
    "    unmatched_entity_names = []\n",
    "    matched_entity_names = []\n",
    "    for entity in entity_names:\n",
    "        if entity.lower() in lower2original.keys():\n",
    "            matched_entity_names.extend(lower2original[entity.lower()])\n",
    "        elif entity != '': #cannot be encoded\n",
    "            unmatched_entity_names.append(entity)\n",
    "    try:\n",
    "        if len(unmatched_entity_names) > 0:\n",
    "            with GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD)) as driver:\n",
    "                res = driver.execute_query(\"\"\"\n",
    "                                        CALL genai.vector.encodeBatch($names, 'OpenAI', { token: $api_key }) YIELD vector AS entityNameEmbs\n",
    "                                        CALL db.index.vector.queryNodes('nameEmbedding', $k, entityNameEmbs) YIELD node\n",
    "                                        RETURN node.name AS name\"\"\", parameters_={'names': unmatched_entity_names, 'k': k, 'api_key': OPENAI_API_KEY})\n",
    "            top1_similar_names = [res.records[i]['name'] for i in range(0,len(res.records),k)]\n",
    "            matched_entity_names += top1_similar_names\n",
    "    except:\n",
    "        print(unmatched_entity_names)\n",
    "    return matched_entity_names\n",
    "\n",
    "def add_entities(data):\n",
    "    question = data['question']\n",
    "    identified_entities = identify_entities(question)\n",
    "    matched_entities = match_entities(identified_entities)\n",
    "    data['predicted_entities'] = matched_entities\n",
    "    return data"
   ],
   "id": "6f85c23737f27fbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_evaluated_paths(driver, src_names: list[str], tgt_ids: list[str]) -> (list[tuple[str, str, str, str]], float, float):\n",
    "    query_1hop = \"\"\"UNWIND $src_names AS srcName\n",
    "                    MATCH (src {name: srcName})-[r]-(tgt)\n",
    "                    \n",
    "                    RETURN labels(src)[1] AS label1, src.name AS name1, type(r) AS type1, labels(tgt)[1] AS label2, size([t IN collect(DISTINCT tgt) WHERE t.nodeId in $tgt_ids| t]) AS correctCnt, count(DISTINCT tgt) AS totalCnt\"\"\"\n",
    "    \n",
    "    query_2hop = \"\"\"UNWIND $src_names AS srcName\n",
    "                    MATCH (src1 {name: srcName})-[r1]-(var)-[r2]-(tgt) WHERE tgt <> src1\n",
    "                    \n",
    "                    RETURN labels(src1)[1] AS label1, src1.name AS name1, type(r1) AS type1, labels(var)[1] AS label2, type(r2) AS type2, labels(tgt)[1] AS label3, size([t IN collect(DISTINCT tgt) WHERE t.nodeId in $tgt_ids| t]) AS correctCnt, count(DISTINCT tgt) AS totalCnt\"\"\"\n",
    "    \n",
    "    query_2path = \"\"\"UNWIND $src_names AS srcName1\n",
    "                     UNWIND $src_names AS srcName2\n",
    "                     MATCH (src1 {name: srcName1})-[r1]-(tgt)-[r2]-(src2 {name: srcName2}) WHERE src1 <> src2\n",
    "    \n",
    "                     RETURN labels(src1)[1] AS label1, src1.name AS name1, type(r1) AS type1, labels(tgt)[1] AS label2, type(r2) AS type2, labels(src2)[1] AS label3, src2.name AS name3, size([t IN collect(DISTINCT tgt) WHERE t.nodeId in $tgt_ids| t]) AS correctCnt, count(DISTINCT tgt) AS totalCnt\"\"\"\n",
    "    \n",
    "    cyphers = []\n",
    "    hits = []\n",
    "    num_results = []\n",
    "    for res in driver.execute_query(query_1hop, parameters_={'src_names': src_names, 'tgt_ids': tgt_ids}).records:\n",
    "        path = [('x', 1, res['label1'], res['name1']), ('r', 1, res['type1'], \"\"), ('x', 2, res['label2'], \"\"), ('', 2, \"\", \"\")]\n",
    "        cyphers.append(path2cypher(path))\n",
    "        hits.append(res['correctCnt'])\n",
    "        num_results.append(res['totalCnt'])\n",
    "        \n",
    "    for res in driver.execute_query(query_2hop, parameters_={'src_names': src_names, 'tgt_ids': tgt_ids}).records:\n",
    "        path = [('x', 1, res['label1'], res['name1']), ('r', 1, res['type1'], \"\"), ('x', 2, res['label2'], \"\"),\n",
    "                      ('r', 2, res['type2'], \"\"), ('x', 3, res['label3'], \"\"), ('', 3, \"\", \"\")]\n",
    "        cyphers.append(path2cypher(path))\n",
    "        hits.append(res['correctCnt'])\n",
    "        num_results.append(res['totalCnt'])\n",
    "        \n",
    "    for res in driver.execute_query(query_2path, parameters_={'src_names': src_names, 'tgt_ids': tgt_ids}).records:\n",
    "        path = [('x', 1, res['label1'], res['name1']), ('r', 1, res['type1'], \"\"), ('x', 2, res['label2'], \"\"),\n",
    "                      ('r', 2, res['type2'], \"\"), ('x', 3, res['label3'], res['name3']), ('', 2, \"\", \"\")]\n",
    "        cyphers.append(path2cypher(path))\n",
    "        hits.append(res['correctCnt'])\n",
    "        num_results.append(res['totalCnt'])\n",
    "\n",
    "    return cyphers, hits, num_results\n",
    "\n",
    "def add_cypher_data(data, driver, include_stats=False):\n",
    "    src_names = data['predicted_entities']\n",
    "    tgt_ids = data['answer_ids'] if include_stats else []\n",
    "    data['cyphers'], data['hits'], data['num_results'] = get_evaluated_paths(driver, src_names, tgt_ids)\n",
    "    return data"
   ],
   "id": "5e26fa354c6f2f42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#All data to load\n",
    "qa = load_from_disk('prime-data/qa')"
   ],
   "id": "a3d41705c2336de2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Entity matching\n",
    "qa_with_ner = qa.map(add_entities, num_proc=8)\n",
    "qa_with_ner.save_to_disk('prime-data/qa_with_ner')"
   ],
   "id": "1ace40702d7d351f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Find all possible patterns from the identified source nodes\n",
    "with GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD)) as driver:\n",
    "    qa_with_cyphers = qa_with_ner.map(lambda x: add_cypher_data(x, driver, include_stats=True), num_proc=8) #includes stats also for test set, make sure to ignore later!\n",
    "qa_with_cyphers['test'] = qa_with_cyphers['test'].remove_columns(['hits', 'num_results'])\n",
    "qa_with_cyphers.save_to_disk('prime-data/qa_with_cyphers')"
   ],
   "id": "b5b1880484e7f351"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
