{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-31T12:21:09.784016Z",
     "start_time": "2025-01-31T12:21:09.779925Z"
    }
   },
   "source": [
    "from neo4j import GraphDatabase\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "from datasets import load_from_disk, DatasetDict\n",
    "\n",
    "from train_llm2 import qa_with_train_prompts\n",
    "\n",
    "load_dotenv('db.env', override=True)\n",
    "NEO4J_URI = os.getenv('NEO4J_URI')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "NEO4J_URI"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bolt://localhost:7687'"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 489
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T14:48:46.199486Z",
     "start_time": "2025-01-31T14:48:45.666880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "id": "276a728cb5f1f334",
   "outputs": [],
   "execution_count": 583
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T12:21:13.550757Z",
     "start_time": "2025-01-31T12:21:13.548397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cypher2path(cypher_query: str) -> list[tuple[str, str, str, str]]:\n",
    "    #path = re.findall(r\"(?:\\(|-\\[)(x|r)(\\d):([^ \\)\\]]+)(?: \\{name: \\\"(.+)\\\"\\})?(?:\\)|\\]-)\", cypher_query)\n",
    "    path = re.findall(r\"(?:\\(|-\\[)(x|r)(\\d):([^ \\)\\]]+)(?: \\{name: \\\"([^\\\"]+)\\\"\\})?(?:\\)|\\]-)\", cypher_query)\n",
    "    return path\n",
    "\n",
    "def block2cypher(x_r: str, num: str, label_or_type: str, name: str) -> str:\n",
    "    if x_r == 'x':\n",
    "        prop_string = f\" {{name: \\\"{name}\\\"}}\" if name != '' else \"\"\n",
    "        return f\"(x{num}:{label_or_type}{prop_string})\"\n",
    "    elif x_r == 'r':\n",
    "        return f\"-[r{num}:{label_or_type}]-\"\n",
    "\n",
    "def path2cypher(path: list[tuple[str, str, str, str]]) -> str:\n",
    "    query = \"MATCH \"\n",
    "    for x_r, num, label_or_type, name in path:\n",
    "        if x_r == 'x' or x_r == 'r':\n",
    "            query += block2cypher(x_r, num, label_or_type, name)\n",
    "        elif x_r == '':\n",
    "            query += f\" RETURN x{num}.name as name\"\n",
    "    return query"
   ],
   "id": "8ddcc94f752ce2bd",
   "outputs": [],
   "execution_count": 491
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T14:34:47.872014Z",
     "start_time": "2025-01-31T14:34:47.866237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def modified_query(cypher_query: str) -> str:\n",
    "    cypher_query = cypher_query.split(\" RETURN\")[0]\n",
    "    path = cypher2path(cypher_query)\n",
    "    _, last_num, _, last_name = path[-1]\n",
    "    tgt = 'x3' if last_num == '3' and last_name == '' else 'x2'\n",
    "    return f\"\"\"{cypher_query} RETURN DISTINCT\n",
    "                                     {tgt}.name AS name, \n",
    "                                     {tgt}.details AS details, \n",
    "                                     {tgt}.nodeId AS node_id,\n",
    "                                     vector.similarity.cosine({tgt}.textEmbedding, $questionEmbedding) AS similarity\n",
    "                               ORDER BY similarity DESC\"\"\"\n",
    "\n",
    "def format_pattern(cypher_query: str, fetched_name: str) -> str:\n",
    "    path = cypher2path(cypher_query)\n",
    "    x_r, num, label, name = path[-1]\n",
    "    if name == '': #src-tgt AND src-var-tgt\n",
    "        path[-1] = (x_r, num, label, fetched_name)\n",
    "    else: #src1-tgt-src2\n",
    "        x_r, num, label, name = path[2]\n",
    "        path[2] = (x_r, num, label, fetched_name)\n",
    "    return path2cypher(path).lstrip(\"MATCH \")\n",
    "\n",
    "def make_description(rec: dict) -> (str, float):\n",
    "    name = rec['name']\n",
    "    patterns = rec.get('patterns', None)\n",
    "    details = rec['details']\n",
    "    if patterns is not None:\n",
    "        patterns_string = ', '.join([format_pattern(pattern, name) for pattern in patterns])\n",
    "    else:\n",
    "        patterns_string = \"No pattern\" #Idea: use cypher to find pattern for vector similar nodes!\n",
    "    return f\"\"\"Name: {name}\\nPatterns: {patterns_string}\\nDescription: {details}\"\"\"\n",
    "\n",
    "def data_fetcher(cypher_queries, question_embedding) -> ([tuple[dict,str], None, None]): #generator which produces db outputs\n",
    "    with GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD)) as driver:\n",
    "        for cypher_query in cypher_queries:\n",
    "            db_query = modified_query(cypher_query)\n",
    "            with driver.session() as session:\n",
    "                for rec in session.run(db_query, parameters={'questionEmbedding': question_embedding}):\n",
    "                    yield rec, cypher_query\n",
    "                \n",
    "def data_fetcher_vector_sim(question_embedding: list[float], max_num_nodes: int, found_node_ids: list[int]) -> ([dict, None, None]):\n",
    "    ef = 5 * max_num_nodes\n",
    "    with GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD)).session() as session:\n",
    "        db_query = \"\"\"CALL db.index.vector.queryNodes('textEmbedding', $numNodes, $questionEmbedding) YIELD node AS node, score\n",
    "                      WHERE NOT node.nodeId IN $foundNodeIds\n",
    "                      RETURN node.name AS name, \n",
    "                             node.details AS details, \n",
    "                             node.nodeId AS node_id,\n",
    "                             score AS similarity\"\"\"\n",
    "        for rec in session.run(db_query, parameters={'numNodes': max_num_nodes, 'questionEmbedding': question_embedding, 'foundNodeIds': found_node_ids}):\n",
    "            yield rec\n",
    "        \n",
    "def get_answer_names(answer_ids: list[int]) -> list[str]:\n",
    "    with GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD)) as driver:\n",
    "        db_query = \"\"\"UNWIND $nodeIds AS nodeId \n",
    "                      MATCH (x:_Entity_ {nodeId: nodeId})\n",
    "                      RETURN x.name as name\"\"\"\n",
    "        res = driver.execute_query(db_query, {'nodeIds': answer_ids})\n",
    "        answer_names = [rec['name'] for rec in res.records]\n",
    "        return answer_names"
   ],
   "id": "b2c051934f5e6347",
   "outputs": [],
   "execution_count": 578
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T14:24:22.312922Z",
     "start_time": "2025-02-03T14:24:22.064641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#MAX_TOKENS = 10_000\n",
    "MAX_TOKENS = 100_000\n",
    "EXTRA_TOKENS_PER_NODE = 10 # To assure we don't hit the context-window max size\n",
    "CYPHER_RATE = .5 #Rest is taken by vector similarity\n",
    "\n",
    "q_embs = torch.load('prime-data/text-embeddings-ada-002/query/query_emb_dict.pt', weights_only=False)\n",
    "\n",
    "def add_retrieved_data(data: dict, driver: GraphDatabase.driver) -> dict:\n",
    "    idx = data['id']\n",
    "    question = data['question']\n",
    "    q_emb = q_embs[idx].tolist()[0]\n",
    "    \n",
    "    answer_names = get_answer_names(eval(data['answer_ids']))\n",
    "    answer = '|'.join(answer_names)\n",
    "    \n",
    "    node_data = {}\n",
    "    num_tokens = len(tokenizer.tokenize(question)) + len(tokenizer.tokenize(answer)) + 10\n",
    "    \n",
    "    for rec, cypher_query in data_fetcher(data['cyphers'], question_embedding=q_emb):\n",
    "        node_id = rec['node_id']\n",
    "        if node_id in node_data.keys(): #already found\n",
    "            num_new_tokens = len(tokenizer.tokenize(cypher_query))\n",
    "            if num_tokens + num_new_tokens > (1-CYPHER_RATE)*MAX_TOKENS:\n",
    "                break\n",
    "            node_data[node_id]['patterns'].append(cypher_query)\n",
    "        else:\n",
    "            num_new_tokens = len(tokenizer.tokenize(cypher_query)) + len(tokenizer.tokenize(rec['details'] if rec['details'] is not None else '')) + EXTRA_TOKENS_PER_NODE\n",
    "            if num_tokens + num_new_tokens > (1-CYPHER_RATE)*MAX_TOKENS:\n",
    "                break\n",
    "            node_data[node_id] = {'name': rec['name'], 'patterns': [cypher_query], 'details': rec['details'], 'similarity': rec['similarity']}\n",
    "        num_tokens += num_new_tokens\n",
    "    # Order by similarity (most similar first) (but append vector-similar to the end)\n",
    "    node_ids = list(node_data.keys())\n",
    "    node_texts = [make_description(val) for val in sorted(node_data.values(), key=lambda x: x['similarity'], reverse=True)] \n",
    "    for rec in data_fetcher_vector_sim(q_emb, max_num_nodes=100, found_node_ids=node_ids):\n",
    "        node_text = make_description(rec)\n",
    "        num_new_tokens = len(tokenizer.tokenize(node_text)) + EXTRA_TOKENS_PER_NODE\n",
    "        if num_tokens + num_new_tokens > MAX_TOKENS:\n",
    "            break\n",
    "        else:\n",
    "            num_tokens += num_new_tokens\n",
    "            node_ids.append(rec['node_id'])\n",
    "            node_texts.append(node_text)\n",
    "            \n",
    "    info = '\\n\\n'.join(node_texts)\n",
    "    data['info'] = info\n",
    "    data['info_nodes'] = node_ids\n",
    "    data['answer'] = answer\n",
    "    return data\n",
    "\n",
    "def sort_cyphers(data: dict) -> dict:\n",
    "    cyphers, hits, num_results = data['cyphers'], data['hits'], data['num_results']\n",
    "    data['cyphers'], data['hits'], data['num_results'] = zip(*sorted(zip(cyphers, hits, num_results), key=lambda x: (-x[1],x[2])))\n",
    "    return data"
   ],
   "id": "54d29b3f316c6c20",
   "outputs": [],
   "execution_count": 715
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T15:33:51.438639Z",
     "start_time": "2025-01-31T15:22:07.015433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qa_with_train_cyphers = load_from_disk('prime-data/qa_with_train_cyphers')\n",
    "\n",
    "qa_with_train_prompts = DatasetDict({'train' : qa_with_train_cyphers['train'], 'valid' : qa_with_train_cyphers['valid']})\n",
    "with GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD)) as driver:\n",
    "    qa_with_train_prompts = qa_with_train_prompts.map(sort_cyphers).map(lambda x: add_retrieved_data(x, driver), num_proc=8)\n",
    "qa_with_train_prompts.save_to_disk('prime-data/qa_with_train_prompts')"
   ],
   "id": "38b05b02707ca3ca",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6162/6162 [00:00<00:00, 11792.11 examples/s]\n",
      "Map: 100%|██████████| 2241/2241 [00:00<00:00, 10854.55 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 6162/6162 [05:55<00:00, 17.32 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 2241/2241 [05:42<00:00,  6.54 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 6162/6162 [00:00<00:00, 73070.84 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2241/2241 [00:00<00:00, 63110.57 examples/s]\n"
     ]
    }
   ],
   "execution_count": 602
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T14:24:32.039167Z",
     "start_time": "2025-02-03T14:24:29.809138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qa_with_gen_cyphers = load_from_disk('prime-data/qa_with_pred_cyphers')\n",
    "\n",
    "qa_with_eval_prompts = DatasetDict({'valid' : qa_with_gen_cyphers['valid']})#, 'test' : qa_with_gen_cyphers['test']})\n",
    "with GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD)) as driver:\n",
    "    qa_with_eval_prompts = qa_with_eval_prompts.map(lambda x: add_retrieved_data(x, driver), num_proc=8)\n",
    "\n",
    "qa_with_eval_prompts.save_to_disk('prime-data/qa_with_eval_prompts_100k')"
   ],
   "id": "62ef12997a2f9c15",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 225/225 [00:00<00:00, 8834.00 examples/s]\n"
     ]
    }
   ],
   "execution_count": 716
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T14:24:46.293676Z",
     "start_time": "2025-02-03T14:24:46.232496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "precs = []; recs = []; f1s = []; num_nodes = []\n",
    "#for qa in qa_with_train_prompts['train']:\n",
    "for qa in qa_with_eval_prompts['valid']:\n",
    "    answer_nodes = eval(qa['answer_ids'])\n",
    "    prompt_nodes = qa['info_nodes']\n",
    "    hits = len(set(answer_nodes).intersection(prompt_nodes))\n",
    "    prec = hits/len(prompt_nodes) if len(prompt_nodes) > 0 else 0\n",
    "    rec = hits/len(answer_nodes)\n",
    "    f1 = (2*prec*rec)/(prec+rec) if hits > 0 else 0\n",
    "    precs.append(prec)\n",
    "    recs.append(rec)\n",
    "    f1s.append(f1)\n",
    "    num_nodes.append(len(prompt_nodes))\n",
    "print(f\"Avg prec:   {np.mean(precs):.3f}\\nAvg rec:    {np.mean(recs):.3f}\\nAvg f1:     {np.mean(f1s):.3f}\\nAvg #nodes: {np.mean(num_nodes):.1f}\\nMed #nodes: {np.median(num_nodes):.1f}\")"
   ],
   "id": "b806eea67b89b9eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg prec:   0.010\n",
      "Avg rec:    0.733\n",
      "Avg f1:     0.019\n",
      "Avg #nodes: 202.4\n",
      "Med #nodes: 185.0\n"
     ]
    }
   ],
   "execution_count": 717
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fe89053379e2eb5f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
